CREATE DATABASE windowfounctions

use windowfounctions;

create table customers
(
    id int,
    name varchar(50)
);

create table orders
(
    order_id int,
    amount int,
    cust_id int
);

insert into customers values(1,'John');
insert into customers values(2,'David');
insert into customers values(3,'Ronn');
insert into customers values(4,'Betty');
insert into orders values(1,100,10);
insert into orders values(2,500,3);
insert into orders values(3,300,6);
insert into orders values(4,800,2);
insert into orders values(5,350,1);
select * from customers;
select * from orders;

# Get the orders information along with customers full details
# if order amount were greater than 400

SELECT
    c.*,
    o.* 
    from orders o
    inner join customers c on o.cust_id=c.id
    where o.amount >400;

# 2nd way

select c.*,o.* 
from orders o
inner join customers c on o.cust_id=c.id and o.amount >400;

# the second one will take less time than the first one
# because the where condition is applied on the join condition
# and not on the result set

# window functions

# PARTITION BY - to divide the result set into partitions
# ORDER BY - to order the result set
# ROW_NUMBER() - to assign a unique number to each row in the result set
# RANK() - to assign a unique number to each row in the result set, but it will assign the same number to rows with the same value
# DENSE_RANK() - to assign a unique number to each row in the result set, but it will assign the same number to rows with the same value and will not leave gaps in the numbering
# NTILE() - to divide the result set into a specified number of groups and assign a unique number to each group
# SUM() - to calculate the sum of a column
# AVG() - to calculate the average of a column  
# MIN() - to calculate the minimum value of a column
# MAX() - to calculate the maximum value of a column
# COUNT() - to calculate the count of a column

create table shop_sales_data
(
    sales_date date,
    shop_id varchar(10),
    sales_amt int
    
);

select * from shop_sales_data;


insert into shop_sales_data values('2022-02-14','S1',200);
insert into shop_sales_data values('2022-02-15','S1',300);
insert into shop_sales_data values('2022-02-14','S2',600);
insert into shop_sales_data values('2022-02-15','S3',500);
insert into shop_sales_data values('2022-02-18','S1',400);
insert into shop_sales_data values('2022-02-17','S2',250);
insert into shop_sales_data values('2022-02-20','S3',300);

select * from shop_sales_data;


# Total count of sales for each shop using window function

select *,
COUNT(*) over(partition by shop_id) as total_sales_COUNT
FROM shop_sales_data;

# COMPARING IT WITH THE NORMAL GROUP BY
select shop_id, 
COUNT(sales_amt) as total_sales_count
from shop_sales_data
group by shop_id;

# also adding order by clause
select *,       
COUNT(*) over(partition by shop_id order by sales_date asc) as total_sales_COUNT
FROM shop_sales_data;

# here the order by clause will not affect the result set but it will affect the numbering of the rows no matter if we put asc or desc
# this concept is known as moving window or moving sum or moving average

# if we only use the order by clause in over clause
# no partition by clause

select *,   
COUNT(*) over(order by sales_amt desc) as total_sales_COUNT
FROM shop_sales_data;

select *,   
sum(sales_amt) over(order by sales_amt desc) as total_sumof_sales
FROM shop_sales_data;

# no partition window will be created and whole result set will be treated as a single partition and sum will be rolling sum

# if we use the partition by clause

select *,
   sum(sales_amt) over(partition by shop_id) as total_sumof_sales
FROM shop_sales_data;
# here the sum will be rolling sum but only for the partitioned data

#IF WE USE PARTITION BY AND ORDER BY CLAUSE TOGETHER
select *,
   sum(sales_amt) over(partition by shop_id order by sales_amt DESC) as total_sum_of_sales   
FROM shop_sales_data;
# here the sum will be rolling sum but only for the partitioned data and ordered by sales_date

#difference between rolling and running sum is that rolling sum will take the previous rows into account 
#and running sum will take the current row into account


create table amazon_sales_data
(
    sales_date date,
    sales_amt int
    
); 

insert into amazon_sales_data values('2022-02-14',200);
insert into amazon_sales_data values('2022-02-15',300);
insert into amazon_sales_data values('2022-02-14',600);
insert into amazon_sales_data values('2022-02-15',500);
insert into amazon_sales_data values('2022-02-18',400);
insert into amazon_sales_data values('2022-02-17',250);
insert into amazon_sales_data values('2022-02-20',300);


SELECT * FROM amazon_sales_data;

# calculate the date wise rolling avg of sales amount
SELECT *,
   AVG(sales_amt) over(order by sales_date) as rolling_avg_sales_amt    
FROM amazon_sales_data;

# Rank(), Row_Number(), Dense_Rank() window functions

insert into shop_sales_data values('2022-02-19','S1',400);
insert into shop_sales_data values('2022-02-20','S1',400);
insert into shop_sales_data values('2022-02-22','S1',300);
insert into shop_sales_data values('2022-02-25','S1',200);
insert into shop_sales_data values('2022-02-15','S2',600);
insert into shop_sales_data values('2022-02-16','S2',600);
insert into shop_sales_data values('2022-02-16','S3',500);
insert into shop_sales_data values('2022-02-18','S3',500);
insert into shop_sales_data values('2022-02-19','S3',300);

select *,
       row_number() over(partition by shop_id order by sales_amount desc) as row_num,
       rank() over(partition by shop_id order by sales_amount desc) as rank_val,
       dense_rank() over(partition by shop_id order by sales_amount desc) as dense_rank_val
from shop_sales_data;

create table employees
(
    emp_id int,
    salary int,
    dept_name VARCHAR(30)

);

insert into employees values(1,10000,'Software');
insert into employees values(2,11000,'Software');
insert into employees values(3,11000,'Software');
insert into employees values(4,11000,'Software');
insert into employees values(5,15000,'Finance');
insert into employees values(6,15000,'Finance');
insert into employees values(7,15000,'IT');
insert into employees values(8,12000,'HR');
insert into employees values(9,12000,'HR');
insert into employees values(10,11000,'HR');

select * from employees;

# Query - get one employee from each department who is getting maximum salary (employee can be random if salary is same)

select 
    tmp.*
from (select *,
        row_number() over(partition by dept_name order by salary desc) as row_num
    from employees) tmp
where tmp.row_num = 1;

# Query - get one employee from each department who is getting maximum salary (employee can be random if salary is same)

select 
    tmp.*
from (select *,
        row_number() over(partition by dept_name order by salary desc) as row_num
    from employees) tmp
where tmp.row_num = 1;

# Query - get all employees from each department who are getting maximum salary
select 
    tmp.*
from (select *,
        rank() over(partition by dept_name order by salary desc) as rank_num
    from employees) tmp
where tmp.rank_num = 1;
  
# Query - get all top 2 ranked employees from each department who are getting maximum salary
select 
    tmp.*
from (select *,
        dense_rank() over(partition by dept_name order by salary desc) as dense_rank_num
    from employees) tmp
where tmp.dense_rank_num <= 2;

# Example for lag and lead
create table daily_sales
(
sales_date date,
sales_amount int
);


insert into daily_sales values('2022-03-11',400);
insert into daily_sales values('2022-03-12',500);
insert into daily_sales values('2022-03-13',300);
insert into daily_sales values('2022-03-14',600);
insert into daily_sales values('2022-03-15',500);
insert into daily_sales values('2022-03-16',200);

select * from daily_sales;

select *,
      lag(sales_amount, 1) over(order by sales_date) as pre_day_sales
from daily_sales;

# Query - Calculate the differnce of sales with previous day sales
# Here null will be derived
select sales_date,
       sales_amount as curr_day_sales,
       lag(sales_amount, 1) over(order by sales_date) as prev_day_sales,
       sales_amount - lag(sales_amount, 1) over(order by sales_date) as sales_diff
from daily_sales;

# Here we can replace null with 0
select sales_date,
       sales_amount as curr_day_sales,
       lag(sales_amount, 1, 0) over(order by sales_date) as prev_day_sales,
       sales_amount - lag(sales_amount, 1, 0) over(order by sales_date) as sales_diff
from daily_sales;

# Diff between lead and lag
select *,
      lag(sales_amount, 1) over(order by sales_date) as pre_day_sales
from daily_sales;

select *,
      lead(sales_amount, 1) over(order by sales_date) as next_day_sales
from daily_sales;

# Diff between lead and lag
select *,
      lag(sales_amount, 1) over(order by sales_date) as pre_day_sales
from daily_sales;

select *,
      lead(sales_amount, 1) over(order by sales_date) as next_day_sales
from daily_sales;


# How to use Frame Clause - Rows BETWEEN
select * from daily_sales;

select *,
      sum(sales_amount) over(order by sales_date rows between 1 preceding and 1 following) as prev_plus_next_sales_sum
from daily_sales;

select *,
      sum(sales_amount) over(order by sales_date rows between 1 preceding and current row) as prev_plus_next_sales_sum
from daily_sales;

select *,
      sum(sales_amount) over(order by sales_date rows between current row and 1 following) as prev_plus_next_sales_sum
from daily_sales;

select *,
      sum(sales_amount) over(order by sales_date rows between 2 preceding and 1 following) as prev_plus_next_sales_sum
from daily_sales;

select *,
      sum(sales_amount) over(order by sales_date rows between unbounded preceding and current row) as prev_plus_next_sales_sum
from daily_sales;

select *,
      sum(sales_amount) over(order by sales_date rows between current row and unbounded following) as prev_plus_next_sales_sum
from daily_sales;

select *,
      sum(sales_amount) over(order by sales_date rows between unbounded preceding and unbounded following) as prev_plus_next_sales_sum
from daily_sales;

# Alternate way to esclude computation of current row
select *,
      sum(sales_amount) over(order by sales_date rows between unbounded preceding and unbounded following) - sales_amount as prev_plus_next_sales_sum
from daily_sales;

# How to work with Range Between

select *,
      sum(sales_amount) over(order by sales_amount range between 100 preceding and 200 following) as prev_plus_next_sales_sum
from daily_sales;

# Calculate the running sum for a week
# Calculate the running sum for a month
insert into daily_sales values('2022-03-20',900);
insert into daily_sales values('2022-03-23',200);
insert into daily_sales values('2022-03-25',300);
insert into daily_sales values('2022-03-29',250);


select * from daily_sales;

select *,
       sum(sales_amount) over(order by sales_date range between interval '6' day preceding and current row) as running_weekly_sum
from daily_sales;

